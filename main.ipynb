{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T17:49:25.043078500Z",
     "start_time": "2024-02-05T17:49:24.006080300Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Loona\\.conda\\envs\\tf310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "print(training_data.train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T17:49:41.924080600Z",
     "start_time": "2024-02-05T17:49:41.867080800Z"
    }
   },
   "id": "a31929ff22870651",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for images, labels in train_dataloader:\n",
    "    print(f\"Shape of Images: {images.shape}\")\n",
    "    print(f\"Shape of labels: {labels.shape}\")\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T17:42:52.656579200Z",
     "start_time": "2024-02-05T17:42:52.655579300Z"
    }
   },
   "id": "aef5c83d71f03ba9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weird_shape = np.ndarray([4, 1, 2, 3])\n",
    "print(f\"Shape of weird: {weird_shape.shape}\")\n",
    "print(weird_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.657579600Z"
    }
   },
   "id": "88a1ca8296097470",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the default computing device."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67c8b8164a9a2d60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Device: {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.659579500Z"
    }
   },
   "id": "d2b427506a10a5b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, training_data):\n",
    "        training_data = self.flatten(training_data)\n",
    "        logits = self.linear_relu_stack(training_data)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.660580100Z"
    }
   },
   "id": "3fa7b1e97052727e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.662579400Z"
    }
   },
   "id": "d899d1c27cf49508",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.664579600Z"
    }
   },
   "id": "25ed67af3cf22f1f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the training work\n",
    "1. Use the model to do a prediction (at first it will be really bad because the ai is basically randomized)\n",
    "2. Take the result and calculate the difference using the loss function\n",
    "3. backpropagate the loss function result and optimize using the optimizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e50b1827fd388c83"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(dataloader: torch.utils.data.DataLoader, model: NeuralNetwork, loss_fn: nn.CrossEntropyLoss,\n",
    "          optimizer: torch.optim.SGD):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(images) # 64 Images\n",
    "            print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "                \n",
    "train(train_dataloader, model, loss_fn, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.665581100Z"
    }
   },
   "id": "fcbb228df2c0498d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(x)\n",
    "print(logits)\n",
    "prediction_probabilities = nn.Softmax(dim=1)(logits)\n",
    "print(prediction_probabilities)\n",
    "label_prediction = prediction_probabilities.argmax(1)\n",
    "print(f\"Label Prediction: {label_prediction}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.666578700Z"
    }
   },
   "id": "c60dd8a032070d2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(dataloader: torch.utils.data.DataLoader, model: NeuralNetwork, loss_fn: nn.CrossEntropyLoss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_fn(prediction, labels).item()\n",
    "            correct += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {100 * correct:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.667579700Z"
    }
   },
   "id": "903bd5fad8f2183d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.669579400Z"
    }
   },
   "id": "5790c97f1912bec7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(model.state_dict(), \"./model.pth\")\n",
    "print(\"Saved PyTorch model state to model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.670579700Z"
    }
   },
   "id": "343815a6629b366",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        image, label = test_data[i][0].to(device), test_data[i][1]\n",
    "        prediction = model(image)\n",
    "        predicted, actual = classes[prediction[0].argmax(0)], classes[label]\n",
    "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.671579700Z"
    }
   },
   "id": "d2416c3aafa207b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = torch.tensor(1, dtype=torch.float)\n",
    "x = torch.rand_like(x, dtype=torch.float)\n",
    "x.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-05T17:42:52.672579400Z"
    }
   },
   "id": "23771856e05600fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# Define the matrix\n",
    "matrix = [[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]]\n",
    "\n",
    "# Get the diagonal from bottom-left to top-right\n",
    "diagonal = [row[i] for i, row in enumerate(matrix[::-1])]\n",
    "\n",
    "print(matrix[0][::-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:27.766063500Z",
     "start_time": "2024-02-14T12:13:27.762062600Z"
    }
   },
   "id": "cb29236adb7dd618",
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
